version: '3.8'

services:
  # MongoDB Service
  mongodb:
    image: mongo:latest
    container_name: mongodb
    ports:
      - "27017:27017"
    volumes:
      - mongo-data:/data/db
    environment:
      MONGO_INITDB_ROOT_USERNAME: root
      MONGO_INITDB_ROOT_PASSWORD: example

  mongo-express:
    image: mongo-express:1.0.0-alpha.4
    environment:
      ME_CONFIG_MONGODB_ADMINUSERNAME: root
      ME_CONFIG_MONGODB_ADMINPASSWORD: example
      ME_CONFIG_MONGODB_SERVER: mongodb
    ports:
      - "8081:8081"
    depends_on:
      - mongodb

  kafka:
    image: confluentinc/cp-kafka:7.4.0
    container_name: kafka
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: "broker,controller"
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka:9093"
      KAFKA_LISTENERS: "PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka:9092"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT"
      KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"
      KAFKA_INTER_BROKER_LISTENER_NAME: "PLAINTEXT"
      KAFKA_LOG_DIRS: "/tmp/kraft-combined-logs"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      CLUSTER_ID: "5Yr1SIgYQz-b-dgRabWx4g"
    ports:
      - "9092:9092"
    volumes:
      - kafka-data:/tmp/kraft-combined-logs

  kafka-connect:
    image: confluentinc/cp-kafka-connect:7.4.0
    ports:
      - "8083:8083"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: kafka:9092
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: "connect-cluster"
      CONNECT_CONFIG_STORAGE_TOPIC: "connect-configs"
      CONNECT_OFFSET_STORAGE_TOPIC: "connect-offsets"
      CONNECT_STATUS_STORAGE_TOPIC: "connect-status"
      CONNECT_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
    depends_on:
      - kafka

  # Spark Master Service
  spark-master:
    image: bitnami/spark:3.4.1
    container_name: spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_DIRS=/tmp
      - SPARK_LOG_DIR=/opt/bitnami/spark/logs
    ports:
      - "8080:8080"
    volumes:
      - spark-master-logs:/opt/bitnami/spark/logs

  # Spark Worker Service
  spark-worker:
    image: bitnami/spark:3.4.1
    container_name: spark-worker
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
      - SPARK_LOG_DIR=/opt/bitnami/spark/logs
    ports:
      - "8081:8081"
    volumes:
      - spark-worker-logs:/opt/bitnami/spark/logs

  # Hadoop https://hub.docker.com/r/apache/hadoop
  hadoop-namenode:
    image: apache/hadoop:3
    hostname: namenode
    command: ["hdfs", "namenode"]
    ports:
      - 9870:9870
    env_file:
      - ./hadoop-config
    environment:
        ENSURE_NAMENODE_DIR: "/tmp/hadoop-root/dfs/name"
  hadoop-datanode:
    image: apache/hadoop:3
    command: ["hdfs", "datanode"]
    env_file:
      - ./hadoop-config      
  hadoop-resourcemanager:
    image: apache/hadoop:3
    hostname: resourcemanager
    command: ["yarn", "resourcemanager"]
    ports:
        - 8088:8088
    env_file:
      - ./hadoop-config
    volumes:
      - ./test.sh:/opt/test.sh
  hadoop-nodemanager:
    image: apache/hadoop:3
    command: ["yarn", "nodemanager"]
    env_file:
      - ./hadoop-config

  # Doris https://doris.apache.org/docs/install/cluster-deployment/run-docker-cluster/
  doris-fe:
    image: apache/doris:2.0.0_alpha-fe-x86_64
    hostname: fe
    environment:
     - FE_SERVERS=fe1:192.168.56.1:9010
     - FE_ID=1
    volumes:
     - /data/fe/doris-meta/:/opt/apache-doris/fe/doris-meta/
     - /data/fe/log/:/opt/apache-doris/fe/log/
  doris-be:
    image: apache/doris:2.0.0_alpha-fe-x86_64
    hostname: be
    environment:
     - FE_SERVERS=fe1:192.168.56.1:9010
     - BE_ADDR=192.168.56.1:9050
    volumes:
     - /data/be/storage/:/opt/apache-doris/be/storage/
     - /data/be/script/:/docker-entrypoint-initdb.d/
    depends_on:
      - doris-fe

networks:
  default:
    name: eth-pipeline-net

volumes:
  mongo-data:
  kafka-data:
  spark-master-logs:
  spark-worker-logs:

# # Zookeeper Service (for Kafka)
# zookeeper:
#   image: wurstmeister/zookeeper:3.4.6
#   container_name: zookeeper
#   ports:
#     - "2181:2181"

# # Kafka Service
# kafka:
#   image: wurstmeister/kafka:2.13-2.7.0
#   container_name: kafka
#   ports:
#     - "9092:9092"
#   environment:
#     KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
#     KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
#     KAFKA_CREATE_TOPICS: "test_topic:1:1"
#   volumes:
#     - /var/run/docker.sock:/var/run/docker.sock