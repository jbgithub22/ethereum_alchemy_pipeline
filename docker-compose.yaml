version: '3.8'

services:
  # MongoDB Service
  mongodb:
    image: mongo:latest
    container_name: mongodb
    ports:
      - "27017:27017"
    volumes:
      - mongo-data:/data/db
    environment:
      MONGO_INITDB_ROOT_USERNAME: root
      MONGO_INITDB_ROOT_PASSWORD: example

  kafka:
    image: confluentinc/cp-kafka:7.4.0
    container_name: kafka
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_KRAFT_MODE: true
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      KAFKA_LOG_DIRS: /var/lib/kafka/data
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_MIN_INSYNC_REPLICAS: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_BROKER_ID: 1
    ports:
      - "9092:9092"
    volumes:
      - kafka-data:/var/lib/kafka/data

  # Spark Master Service
  spark-master:
    image: bitnami/spark:3.4.1
    container_name: spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_DIRS=/tmp
      - SPARK_LOG_DIR=/opt/bitnami/spark/logs
    ports:
      - "8080:8080"
    volumes:
      - spark-master-logs:/opt/bitnami/spark/logs

  # Spark Worker Service
  spark-worker:
    image: bitnami/spark:3.4.1
    container_name: spark-worker
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
      - SPARK_LOG_DIR=/opt/bitnami/spark/logs
    ports:
      - "8081:8081"
    volumes:
      - spark-worker-logs:/opt/bitnami/spark/logs

  # Hadoop https://hub.docker.com/r/apache/hadoop
  hadoop-namenode:
    image: apache/hadoop:3
    hostname: namenode
    command: ["hdfs", "namenode"]
    ports:
      - 9870:9870
    env_file:
      - ./hadoop-config
    environment:
        ENSURE_NAMENODE_DIR: "/tmp/hadoop-root/dfs/name"
  hadoop-datanode:
    image: apache/hadoop:3
    command: ["hdfs", "datanode"]
    env_file:
      - ./hadoop-config      
  hadoop-resourcemanager:
    image: apache/hadoop:3
    hostname: resourcemanager
    command: ["yarn", "resourcemanager"]
    ports:
        - 8088:8088
    env_file:
      - ./hadoop-config
    volumes:
      - ./test.sh:/opt/test.sh
  hadoop-nodemanager:
    image: apache/hadoop:3
    command: ["yarn", "nodemanager"]
    env_file:
      - ./hadoop-config

  # Doris https://doris.apache.org/docs/install/cluster-deployment/run-docker-cluster/
  doris-fe:
    image: apache/doris:2.0.0_alpha-fe-x86_64
    hostname: fe
    environment:
     - FE_SERVERS=fe1:192.168.56.1:9010
     - FE_ID=1
    volumes:
     - /data/fe/doris-meta/:/opt/apache-doris/fe/doris-meta/
     - /data/fe/log/:/opt/apache-doris/fe/log/
  doris-be:
    image: apache/doris:2.0.0_alpha-fe-x86_64
    hostname: be
    environment:
     - FE_SERVERS=fe1:192.168.56.1:9010
     - BE_ADDR=192.168.56.1:9050
    volumes:
     - /data/be/storage/:/opt/apache-doris/be/storage/
     - /data/be/script/:/docker-entrypoint-initdb.d/
    depends_on:
      - doris-fe

volumes:
  mongo-data:
  kafka-data:
  spark-master-logs:
  spark-worker-logs:
  

# # Zookeeper Service (for Kafka)
# zookeeper:
#   image: wurstmeister/zookeeper:3.4.6
#   container_name: zookeeper
#   ports:
#     - "2181:2181"

# # Kafka Service
# kafka:
#   image: wurstmeister/kafka:2.13-2.7.0
#   container_name: kafka
#   ports:
#     - "9092:9092"
#   environment:
#     KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
#     KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
#     KAFKA_CREATE_TOPICS: "test_topic:1:1"
#   volumes:
#     - /var/run/docker.sock:/var/run/docker.sock